{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48dd64a3",
   "metadata": {},
   "source": [
    "Select a binary classification dataset (e.g., predicting customer churn). Implement a\n",
    "Logistic Regression model. Preprocess the data, including handling categorical\n",
    "variables (if any). Evaluate the model's performance using metrics like accuracy,\n",
    "precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5c94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial Data (X) ---\n",
      "   pclass     sex   age  sibsp  parch     fare embarked\n",
      "0       3    male  22.0      1      0   7.2500        S\n",
      "1       1  female  38.0      1      0  71.2833        C\n",
      "2       3  female  26.0      0      0   7.9250        S\n",
      "3       1  female  35.0      1      0  53.1000        S\n",
      "4       3    male  35.0      0      0   8.0500        S\n",
      "\n",
      "--- Data Info (Note missing values and object types) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    891 non-null    int64  \n",
      " 1   sex       891 non-null    object \n",
      " 2   age       714 non-null    float64\n",
      " 3   sibsp     891 non-null    int64  \n",
      " 4   parch     891 non-null    int64  \n",
      " 5   fare      891 non-null    float64\n",
      " 6   embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 48.9+ KB\n",
      "\n",
      "Training set size: 712\n",
      "Test set size: 179\n",
      "\n",
      "--- Training the model ---\n",
      "--- Model training complete ---\n",
      "\n",
      "--- Model Performance Evaluation ---\n",
      "Accuracy:  0.7989\n",
      "Precision: 0.7794\n",
      "Recall:    0.7162\n",
      "\n",
      "--- Full Classification Report ---\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Did Not Survive (0)       0.81      0.86      0.83       105\n",
      "       Survived (1)       0.78      0.72      0.75        74\n",
      "\n",
      "           accuracy                           0.80       179\n",
      "          macro avg       0.80      0.79      0.79       179\n",
      "       weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns  # <-- 1. Import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "# We no longer need fetch_openml\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "\n",
    "# 2. Load the dataset from Seaborn (this is more stable)\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Define our features (X) and target (y)\n",
    "target_col = 'survived'\n",
    "# 3. Use lowercase column names to match the seaborn dataset\n",
    "feature_cols = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col] # Already in 0/1 integer format\n",
    "\n",
    "print(\"--- Initial Data (X) ---\")\n",
    "print(X.head())\n",
    "print(\"\\n--- Data Info (Note missing values and object types) ---\")\n",
    "X.info()\n",
    "\n",
    "# --- 2. Split Data ---\n",
    "# Split *before* preprocessing to prevent data leakage from the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# --- 3. Define Preprocessing Pipelines ---\n",
    "\n",
    "# Pipeline for NUMERIC features:\n",
    "numeric_features = ['age', 'fare', 'sibsp', 'parch'] # <-- lowercase\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for CATEGORICAL features:\n",
    "categorical_features = ['embarked', 'sex', 'pclass'] # <-- lowercase\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# --- 4. Combine Pipelines with ColumnTransformer ---\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "# --- 5. Create and Train the Full Model Pipeline ---\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the entire pipeline on the training data\n",
    "print(\"\\n--- Training the model ---\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"--- Model training complete ---\")\n",
    "\n",
    "\n",
    "# --- 6. Evaluate the Model ---\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate individual metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"\\n--- Model Performance Evaluation ---\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "\n",
    "# Display a full classification report\n",
    "print(\"\\n--- Full Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Did Not Survive (0)', 'Survived (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da2af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
